// revision: b596cbbe0b642858aae4fe6947670712b6f16f8b

%derive<Show> Token
%derive<Show> ParseError
%position<@ast_types.Position>

%start<@ast.Program> start

%token<CharLiteral> CHAR
%token<String> INT
%token<CharLiteral> BYTE
%token<StringLiteral> BYTES
%token<String> FLOAT
%token<StringLiteral> STRING
%token<String> MULTILINE_STRING
%token<InterpLiteral> MULTILINE_INTERP
%token<InterpLiteral> INTERP
%token<String> ATTRIBUTE
%token<String> LIDENT
%token<String> UIDENT
%token LIDENT_LEX "lex"
%token UIDENT_BYTES_REGEX "BytesRegex"
%token<String> POST_LABEL
%token<Comment> COMMENT
%token NEWLINE
%token<String> INFIX1
%token<String> INFIX2
%token<String> INFIX3
%token<String> INFIX4
%token<String> AUGMENTED_ASSIGNMENT
%token EOF
%token FALSE
%token TRUE
%token PUB "pub"
%token PRIV "priv"
%token READONLY "readonly"
%token IMPORT "import"
%token EXTERN "extern"
%token BREAK "break"
%token CONTINUE "continue"
%token STRUCT "struct"
%token ENUM "enum"
%token TRAIT "trait"
%token DERIVE "derive"
%token IMPL "impl"
%token WITH "with"
%token RAISE "raise"
%token THROW "throw"
%token TRY "try"
%token CATCH "catch"
%token ASYNC "async"
%token TYPEALIAS "typealias"
%token TRAITALIAS "traitalias"
%token FNALIAS "fnalias"
%token EQUAL "="
%token LPAREN "("
%token RPAREN ")"
%token COMMA ","
%token MINUS "-"
%token QUESTION "?"
%token EXCLAMATION "!"
%token<String> DOT_LIDENT
%token<String> DOT_UIDENT
%token<Int> DOT_INT
%token DOT_LPAREN ".("
%token COLONCOLON "::"
%token COLON ":"
%token<Bool> SEMI ";"
%token LBRACKET "["
%token PLUS "+"
%token RBRACKET "]"
%token UNDERSCORE "_"
%token BAR "|"
%token LBRACE "{"
%token RBRACE "}"
%token AMPERAMPER "&&"
%token AMPER "&"
%token CARET "^"
%token BARBAR "||"
%token<String> PACKAGE_NAME
%token AS "as"
%token PIPE "|>"
%token ELSE "else"
%token FN "fn"
%token IF "if"
%token LET "let"
%token CONST "const"
%token MATCH "match"
%token MUTABLE "mut"
%token TYPE "type"
%token FAT_ARROW "=>"
%token THIN_ARROW "->"
%token WHILE "while"
%token RETURN "return"
%token DOTDOT ".."
%token RANGE_INCLUSIVE "..="
%token RANGE_EXCLUSIVE "..<"
%token ELLIPSIS "..."
%token TEST "test"
%token LOOP "loop"
%token GUARD "guard"
%token FOR "for"
%token IN "in"
%token IS "is"

%right CHAR INT BYTE BYTES FLOAT STRING MULTILINE_STRING MULTILINE_INTERP INTERP ATTRIBUTE LIDENT UIDENT LIDENT_LEX UIDENT_BYTES_REGEX POST_LABEL COMMENT NEWLINE INFIX1 INFIX2 INFIX3 INFIX4 AUGMENTED_ASSIGNMENT EOF FALSE TRUE PUB PRIV READONLY IMPORT EXTERN BREAK CONTINUE STRUCT ENUM TRAIT DERIVE IMPL WITH RAISE THROW TRY CATCH ASYNC TYPEALIAS TRAITALIAS FNALIAS EQUAL LPAREN RPAREN COMMA MINUS QUESTION EXCLAMATION DOT_LIDENT DOT_UIDENT DOT_INT DOT_LPAREN COLONCOLON COLON SEMI LBRACKET PLUS RBRACKET UNDERSCORE BAR LBRACE RBRACE AMPERAMPER AMPER CARET BARBAR PACKAGE_NAME AS PIPE ELSE FN IF LET CONST MATCH MUTABLE TYPE FAT_ARROW THIN_ARROW WHILE RETURN DOTDOT RANGE_INCLUSIVE RANGE_EXCLUSIVE ELLIPSIS TEST LOOP GUARD FOR IN IS
%nonassoc prec_HIGHEST

%{
fn mkloc(loc : (Position, Position)) -> Location {
  {start: loc.0, end: loc.1}
}

fn normalize(terms : Array[@ast.Term]) -> Array[@ast.Term] {
  let terms = terms
    .iter()
    .flat_map(fn (term) {
      if term is Nested(terms, ..) {
        terms.iter()
      } else {
        Iter::singleton(term)
      }
    })
    .to_array()
  match terms {
    [] => []
    [x] => [x]
    terms => {
      let first_start = terms[0].loc().start
      let last_end = terms[terms.length() - 1].loc().end
      let mut last = first_start
      let new_terms : Array[@ast.Term] = []
      for term in terms {
        if term is (Nested(_) | NamedRegex(_) | LexDef(_)) {
          let term_start = term.loc().start
          let term_end = term.loc().end
          if term_start > last {
            new_terms.push(Code(loc={start: last, end: term_start}))
          }
          new_terms.push(term)
          last = term_end
        }
      }
      if last < last_end {
        new_terms.push(Code(loc={start: last, end: last_end}))
      }
      new_terms
    }
  }
}
%}

%%

start -> @ast.Program
  : terms { {body: Nested($1, loc=mkloc($sloc)), loc: mkloc($sloc)} }
  ;

terms -> Array[@ast.Term]
  : term_list { normalize($1.to_array()) }
  ;

term_list -> @list.T[@ast.Term]
  : { @list.empty() }
  | term term_list { @list.prepend($2, $1) }
  ;

term -> @ast.Term
  : "const" uident ":" "BytesRegex" "=" regex ";" %prec prec_HIGHEST { NamedRegex($2, $6, loc=mkloc($sloc)) }
  | "lex" lident "{" lex_cases "}" { LexDef($2, $4.to_array(), loc=mkloc($sloc)) }
  | simple_term { Code(loc=mkloc($sloc)) }
  | grouped_term {
    let (loc1, terms, loc2) = $1
    match normalize([Code(loc=loc1), ..terms, Code(loc=loc2)]) {
      [Code(_)] => Code(loc=mkloc($sloc))
      terms => Nested(terms, loc=mkloc($sloc))
    }
  }
  ;

lex_cases -> @list.T[@ast.LexCase]
  : lex_case { @list.singleton($1) }
  | lex_case ";" { @list.singleton($1) }
  | lex_case ";" lex_cases { @list.prepend($3, $1) }
  ;

lex_case -> @ast.LexCase
  : regex_pattern "=>" braced_term { {pattern: $1.to_array(), action: $3, loc: mkloc($sloc)} }
  ;

regex_pattern -> @list.T[@ast.LexPatternItem]
  : regex_pattern_item { @list.singleton($1) }
  | regex_pattern_item "," regex_pattern { @list.prepend($3, $1) }
  ;

regex_pattern_item -> @ast.LexPatternItem
  : regex { Regex($1) }
  | regex "as" lident { RegexAs($1, $3, loc=mkloc($sloc)) }
  ;

regex -> @ast.Regex
  : STRING { Literal($1, loc=mkloc($sloc)) }
  | INTERP { Interp($1, loc=mkloc($sloc)) }
  | uident { Named($1) }
  ;

braced_term -> @ast.Term
  : "{" terms "}" { 
    match normalize([Code(loc=mkloc($loc($1))), ..$2, Code(loc=mkloc($loc($3)))]) {
      [Code(_)] => Code(loc=mkloc($sloc))
      terms => Nested(terms, loc=mkloc($sloc))
    }
  }
  ;

grouped_term -> (Location, Array[@ast.Term], Location)
  : "(" terms ")" { (mkloc($loc($1)), $2, mkloc($loc($3))) }
  | "{" terms "}" { (mkloc($loc($1)), $2, mkloc($loc($3))) }
  | "[" terms "]" { (mkloc($loc($1)), $2, mkloc($loc($3))) }
  ;

%inline simple_term
  : CHAR {}
  | INT {}
  | BYTE {}
  | BYTES {}
  | FLOAT {}
  | STRING {}
  | MULTILINE_STRING {}
  | MULTILINE_INTERP {}
  | INTERP {}
  | ATTRIBUTE {}
  | LIDENT {}
  | UIDENT {}
  | LIDENT_LEX {}
  | UIDENT_BYTES_REGEX {}
  | POST_LABEL {}
  | COMMENT {}
  | NEWLINE {}
  | INFIX1 {}
  | INFIX2 {}
  | INFIX3 {}
  | INFIX4 {}
  | AUGMENTED_ASSIGNMENT {}
  | EOF {}
  | FALSE {}
  | TRUE {}
  | PUB {}
  | PRIV {}
  | READONLY {}
  | IMPORT {}
  | EXTERN {}
  | BREAK {}
  | CONTINUE {}
  | STRUCT {}
  | ENUM {}
  | TRAIT {}
  | DERIVE {}
  | IMPL {}
  | WITH {}
  | RAISE {}
  | THROW {}
  | TRY {}
  | CATCH {}
  | ASYNC {}
  | TYPEALIAS {}
  | TRAITALIAS {}
  | FNALIAS {}
  | EQUAL {}
//  | LPAREN {}
//  | RPAREN {}
  | COMMA {}
  | MINUS {}
  | QUESTION {}
  | EXCLAMATION {}
  | DOT_LIDENT {}
  | DOT_UIDENT {}
  | DOT_INT {}
  | DOT_LPAREN {}
  | COLONCOLON {}
  | COLON {}
  | SEMI {}
//  | LBRACKET {}
  | PLUS {}
//  | RBRACKET {}
  | UNDERSCORE {}
  | BAR {}
//  | LBRACE {}
//  | RBRACE {}
  | AMPERAMPER {}
  | AMPER {}
  | CARET {}
  | BARBAR {}
  | PACKAGE_NAME {}
  | AS {}
  | PIPE {}
  | ELSE {}
  | FN {}
  | IF {}
  | LET {}
  | CONST {}
  | MATCH {}
  | MUTABLE {}
  | TYPE {}
  | FAT_ARROW {}
  | THIN_ARROW {}
  | WHILE {}
  | RETURN {}
  | DOTDOT {}
  | RANGE_INCLUSIVE {}
  | RANGE_EXCLUSIVE {}
  | ELLIPSIS {}
  | TEST {}
  | LOOP {}
  | GUARD {}
  | FOR {}
  | IN {}
  | IS {}
  ;

uident -> @ast.Ident
  : UIDENT { {name: $1, loc: mkloc($sloc)} }
  ;

lident -> @ast.Ident
  : LIDENT { {name: $1, loc: mkloc($sloc)} }
  ;
